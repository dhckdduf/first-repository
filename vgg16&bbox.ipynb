{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMdt095opDbwrGGf0RbK8F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhckdduf/first-repository/blob/main/vgg16%26bbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time"
      ],
      "metadata": {
        "id": "FRDGnBiBYfYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aw9PsquQYYJE"
      },
      "outputs": [],
      "source": [
        "# Google Colab 환경 설정 (GPU 사용 가능 여부 확인)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드 및 압축 해제\n",
        "dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "dataset_path = \"/content/cats_and_dogs_filtered.zip\"\n",
        "dataset_extract_path = \"/content/dataset\"\n",
        "\n",
        "if not os.path.exists(dataset_extract_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
        "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content\")\n",
        "    print(\"Dataset extracted successfully.\")\n",
        "else:\n",
        "    print(\"Dataset already exists.\")"
      ],
      "metadata": {
        "id": "zIzoNkurYkuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 문항 출력\n",
        "print(\"평가 문항\")\n",
        "print(\"1. VGG16 모델을 구현할 수 있는가? - 이미지로 제시된 VGG16 모델을 코드로 구현하였다.\")\n",
        "print(\"2. 다양한 방법을 사용하여 성능을 향상시켰는가? - 다양한 방법을 사용하여 accuracy 53% 이상을 달성하였다.\")\n",
        "print(\"3. 다양한 이미지와 모델을 사용하여 Object Detection을 수행하였는가? - 제시된 이미지 외의 다른 이미지에 Object Detection을 수행하였고, 1가지 이상의 사전 학습된 모델을 사용하여 결과를 비교하였다.\")\n"
      ],
      "metadata": {
        "id": "Nnjs9sA6YmXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 기반 모델 생성\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "84XycJJvYoHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sSPtgoxuYt57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 경로 설정\n",
        "train_data_path = \"/content/cats_and_dogs_filtered/train\"\n",
        "validation_data_path = \"/content/cats_and_dogs_filtered/validation\"\n",
        "\n",
        "# 데이터 증강 및 로드\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = train_datagen.flow_from_directory(\n",
        "    train_data_path, target_size=(224, 224), batch_size=16, class_mode='binary')\n",
        "\n",
        "val_data_gen = val_datagen.flow_from_directory(\n",
        "    validation_data_path, target_size=(224, 224), batch_size=16, class_mode='binary')\n"
      ],
      "metadata": {
        "id": "w-yvhPZmZfAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "history = model.fit(train_data_gen, epochs=10, validation_data=val_data_gen)\n",
        "\n",
        "# 학습 결과 출력\n",
        "print(\"최종 학습 정확도:\", history.history['accuracy'][-1])\n",
        "print(\"최종 검증 정확도:\", history.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "id": "zZgQzHB4aIy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Detection 모델 로드 및 실행\n",
        "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
        "detector = hub.load(module_handle).signatures['default']\n",
        "\n",
        "def load_img(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    return img\n",
        "\n",
        "def display_image(image):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "def run_detector(detector, image_path):\n",
        "    img = load_img(image_path)\n",
        "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "    start_time = time.time()\n",
        "    result = detector(converted_img)\n",
        "    end_time = time.time()\n",
        "    result = {key:value.numpy() for key,value in result.items()}\n",
        "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "    print(\"Inference time: \", end_time-start_time)\n",
        "    display_image(img.numpy())"
      ],
      "metadata": {
        "id": "OVQIV0ehbCVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 이미지 테스트\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/3/3f/JPEG_example_flower.jpg\"\n",
        "image_path = \"/content/sample.jpg\"\n",
        "urllib.request.urlretrieve(image_url, image_path)\n",
        "run_detector(detector, image_path)\n"
      ],
      "metadata": {
        "id": "rF8WHwgRciAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lk_zcFREcptB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}